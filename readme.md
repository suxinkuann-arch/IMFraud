# ğŸ•µï¸ AI Dialogue Generator for Fraud Detection Research

## ğŸ“– Overview

This project provides a comprehensive framework for generating and processing dialogue datasets specifically designed for fraud detection AI training. The system creates both fraudulent (positive) and non-fraudulent (negative) dialogue examples using multiple AI models.

## ğŸš€ Quick Start

### Dialog Generation

**Fraudulent Dialogues (Positive Examples)**

```
# Configure API settings in config/settings/
python main_with_background.py
```

### Non-Fraudulent Dialogues (Negative Examples)

```
# Configure prompts in config/settings/
python src/main.py
```

## ğŸ“Š Modules

### ğŸ” Dialog | Fraudulent Dialogue Generation

**Purpose**: Generate realistic fraudulent conversations for training detection models

**Features**:

- 

  ğŸ¤– **Multi-Model Support**: Utilizes DeepSeek, DouBao, and Kimi AI models

- 

  ğŸ“° **Real-based Generation**: Trained on actual scam cases from Fraud_News_Reports dataset

- 

  âš™ï¸ **Configurable**: Easy API and dataset path configuration

**Usage**:

1. 

   Edit model configurations in `config/settings/`

2. 

   Run generation script

3. 

   Output: Authentic fraudulent dialogue dataset

### ğŸ›¡ï¸ NotFraudDialog | Benign Dialogue Generation

**Purpose**: Create non-fraudulent conversations to balance training data

**Features**:

- 

  ğŸ­ **Scenario-based**: Uses predefined scenarios from `src/core/dialogue_generator.py`

- 

  âš–ï¸ **Balanced Data**: Ensures diverse non-fraudulent examples

- 

  ğŸ”§ **Customizable**: Easy prompt engineering for different scenarios

### ğŸ’¾ DataHandle | Data Processing Pipeline

#### ğŸ”„ Processing Flow

```
Raw Data â†’ Merge â†’ Deduplicate â†’ Anonymize â†’ Filter â†’ Split â†’ Balance â†’ Final Dataset
```

#### ğŸ“ Scripts Overview

**`main2.py`** - Preliminary Processing

- 

  **Input**: Raw generated dialogues

- 

  **Processing**: Merging + Deduplication + Anonymization

- 

  **Output**: Analysis-ready data for threshold determination

**`main.py`** - Full Pipeline

- 

  **Input**: Preliminary processed data

- 

  **Processing**: Length filtering + Dataset splitting + Class balancing

- 

  **Output**: Final training-ready dataset

#### ğŸ› ï¸ Tools

**`csvDistribution`** - Statistical Analysis

- 

  ğŸ“ˆ Generates distribution plots and statistics

- 

  ğŸ“ Calculates median lengths for dialogue segmentation

- 

  ğŸ¯ Determines optimal length thresholds

**`DeleteNum`** - Threshold Optimization

- 

  ğŸ“Š Analyzes anonymized data characteristics

- 

  âš¡ Identifies optimal filtering parameters

- 

  ğŸ” Ensures data quality standards

## ğŸ‹ï¸ Training & Evaluation

### Model Training

```
# Configure paths in config/config.py
torchrun --nproc_per_node=x main.py
```

### Evaluation

**`test.py`** - Model Performance Assessment

- 

  ğŸ§ª Evaluate base model (leave CheckPoint empty)

- 

  ğŸ”— Evaluate fine-tuned model (specify CheckPoint path)

- 

  ğŸ“Š Comprehensive performance metrics

## âš™ï¸ Configuration

### Settings Structure

```
config/
â””â”€â”€ settings/
    â”œâ”€â”€ model_apis.yaml      # AI model configurations
    â”œâ”€â”€ dataset_paths.yaml   # Data source paths
    â””â”€â”€ processing_params.yaml # Processing parameters
```

## ğŸ“ˆ Output

- 

  ğŸ—‚ï¸ Balanced dialogue datasets (fraud/benign)

- 

  ğŸ“Š Statistical analysis reports

- 

  ğŸ¯ Optimized training-ready data splits

- 

  ğŸ“ Comprehensive documentation

------

*This project supports academic research in fraud detection and AI security. Use responsibly.*